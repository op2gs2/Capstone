{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''각종 라이브러리 import'''\n",
    "# 인공지능 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# 파이썬 라이브러리\n",
    "import os\n",
    "import time\n",
    "# 이미지 관련 라이브러리\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "악성 파일 처리중\n"
     ]
    }
   ],
   "source": [
    "# 악성코드 데이터 불러오기\n",
    "'''\n",
    "normal_image = glob.glob(r\"D:\\OneDrive - 한림대학교\\바탕 화면\\Working Space\\Capstone\\dataset\\image\\normal\\*thumb.png \")\n",
    "\n",
    "# 일반 데이터를 저장할 배열 생성\n",
    "nor_len = 800 #len(os.listdir(r\"D:\\OneDrive - 한림대학교\\바탕 화면\\Working Space\\Capstone\\dataset\\image\\normal\\ \"))\n",
    "normal_input = np.zeros((nor_len,28,28,1), dtype=\"float32\")\n",
    "normal_target = np.zeros((nor_len), dtype=\"uint8\")\n",
    "\n",
    "# 이미지를 불러온 후, 28*28로 조정\n",
    "cnt = 0\n",
    "print(\"일반 파일 처리중\")\n",
    "for i in normal_image:\n",
    "    #print(cnt,\"번째 처리중: \",i)\n",
    "    im = Image.open(i).convert(\"L\")\n",
    "    out = im.resize((28,28))\n",
    "    normal_input[cnt,:,:,0] = out\n",
    "    normal_target[cnt] = 0 # normal = 0\n",
    "    cnt = cnt + 1\n",
    "'''\n",
    "# 악성코드 데이터 불러오기\n",
    "malware_image = glob.glob(r\"D:\\OneDrive - 한림대학교\\바탕 화면\\Working Space\\Capstone\\dataset\\image\\malware\\*thumb.png\")\n",
    "\n",
    "# 악성코드 데이터를 저장할 배열 생성\n",
    "mal_len = 39284 #len(os.listdir(r'D:\\OneDrive - 한림대학교\\바탕 화면\\Working Space\\Capstone\\dataset\\image\\malware\\ ')) # 샘플의 갯수\n",
    "malware_input = np.zeros((mal_len,28,28,1), dtype=\"float32\")\n",
    "malware_target = np.zeros(mal_len, dtype=\"uint8\")\n",
    "\n",
    "# 이미지를 불러온 후, 28*28로 조정\n",
    "cnt = 0\n",
    "print(\"악성 파일 처리중\")\n",
    "for i in malware_image:\n",
    "    #print(cnt,\"번째 처리중: \",i)\n",
    "    im = Image.open(i).convert(\"L\")\n",
    "    out = im.resize((28,28))\n",
    "    malware_input[cnt,:,:,0] = out\n",
    "    malware_target[cnt] = 1 # malware = 1\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "# 데이터 합치기\n",
    "\n",
    "input_data = malware_input\n",
    "target_data = malware_target\n",
    "\n",
    "#input_data = np.concatenate((normal_input, malware_input), axis=0)\n",
    "#target_data = np.concatenate((normal_target, malware_target),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(39284, 28, 28, 1)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 분리하기\n",
    "train_input, test_input, train_target, test_target = train_test_split(input_data, target_data, test_size=0.3)\n",
    "\n",
    "train_scaled = train_input.reshape(-1,28,28,1) / 255.0\n",
    "test_scaled = test_input.reshape(-1,28,28,1) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,155,073\n",
      "Trainable params: 17,155,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "'''합성곱 신경망 만들기'''\n",
    "with tf.device('/CPU:0'):\n",
    "    # 합성곱 신경망\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st Layer\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size = (3,3), activation = 'relu', padding = 'same', input_shape = (28,28,1), strides= (1,1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = 'same'))\n",
    "    model.add(keras.layers.Dropout(0.8))\n",
    "\n",
    "    # 2nd Layer\n",
    "    model.add(keras.layers.Conv2D(128, kernel_size = (3,3), activation = 'relu', padding = 'same', strides= (1,1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = 'same'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    # 3rd Layer\n",
    "    model.add(keras.layers.Conv2D(256, kernel_size = (3,3), activation = 'relu', padding = 'same', strides= (1,1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = 'same'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "\n",
    "    # 4th Layer\n",
    "    model.add(keras.layers.Dense(4096, activation = 'relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    # 5th Layer\n",
    "    model.add(keras.layers.Dense(1, activation = 'softmax'))\n",
    "\n",
    "    # 모델에 대한 시각화\n",
    "    model.summary() # 모델의 구조 보기\n",
    "    keras.utils.plot_model(model) # 모델의 구조를 그림으로 표현\n",
    "    keras.utils.plot_model(model, show_shapes=True) # 모델의 구조를 그림으로 표현하며, 입력값의 shape도 출력\n",
    "\n",
    "    # Model Compile\n",
    "    model.compile(optimizer = 'adam', loss = keras.losses.BinaryCrossentropy(), metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 Fold 처리중\n",
      "Epoch 1/100\n",
      "2200/2200 [==============================] - 121s 55ms/step - loss: 4.3927e-18 - accuracy: 1.0000 - val_loss: 5.9084e-15 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "2200/2200 [==============================] - 119s 54ms/step - loss: 2.1736e-18 - accuracy: 1.0000 - val_loss: 5.9084e-15 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "2200/2200 [==============================] - 119s 54ms/step - loss: 4.4514e-19 - accuracy: 1.0000 - val_loss: 5.9084e-15 - val_accuracy: 1.0000\n",
      "1 번째 Fold 처리중\n",
      "Epoch 1/100\n",
      "2200/2200 [==============================] - 121s 55ms/step - loss: 2.5651e-17 - accuracy: 1.0000 - val_loss: 5.7601e-12 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "2200/2200 [==============================] - 123s 56ms/step - loss: 4.0911e-18 - accuracy: 1.0000 - val_loss: 5.7601e-12 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "2200/2200 [==============================] - 123s 56ms/step - loss: 2.1931e-18 - accuracy: 1.0000 - val_loss: 5.7601e-12 - val_accuracy: 1.0000\n",
      "2 번째 Fold 처리중\n",
      "Epoch 1/100\n",
      "2200/2200 [==============================] - 124s 57ms/step - loss: 7.1868e-18 - accuracy: 1.0000 - val_loss: 4.1010e-12 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "2200/2200 [==============================] - 124s 56ms/step - loss: 2.6493e-18 - accuracy: 1.0000 - val_loss: 4.1010e-12 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "2200/2200 [==============================] - 124s 56ms/step - loss: 3.2530e-18 - accuracy: 1.0000 - val_loss: 4.1010e-12 - val_accuracy: 1.0000\n",
      "3 번째 Fold 처리중\n",
      "Epoch 1/100\n",
      "2200/2200 [==============================] - 125s 57ms/step - loss: 4.2285e-18 - accuracy: 1.0000 - val_loss: 6.0801e-12 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "2200/2200 [==============================] - 124s 56ms/step - loss: 3.2919e-18 - accuracy: 1.0000 - val_loss: 6.0801e-12 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "2200/2200 [==============================] - 124s 57ms/step - loss: 4.8707e-18 - accuracy: 1.0000 - val_loss: 6.0801e-12 - val_accuracy: 1.0000\n",
      "4 번째 Fold 처리중\n",
      "Epoch 1/100\n",
      "2200/2200 [==============================] - 127s 58ms/step - loss: 3.2934e-20 - accuracy: 1.0000 - val_loss: 4.2056e-11 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "2200/2200 [==============================] - 125s 57ms/step - loss: 2.1672e-20 - accuracy: 1.0000 - val_loss: 4.2056e-11 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "2200/2200 [==============================] - 125s 57ms/step - loss: 4.1269e-20 - accuracy: 1.0000 - val_loss: 4.2056e-11 - val_accuracy: 1.0000\n",
      "369/369 [==============================] - 4s 12ms/step - loss: 8.0844e-13 - accuracy: 1.0000\n",
      "실행시간:  1853.2135517597198\n"
     ]
    }
   ],
   "source": [
    "'''모델 컴파일과 훈련'''\n",
    "with tf.device('/CPU:0'):\n",
    "    k = 5\n",
    "    num_epochs = 100\n",
    "    batch = 10\n",
    "\n",
    "    num_val_samples = len(train_input) // k\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in range(k):\n",
    "        print(i,'번째 Fold 처리중')\n",
    "\n",
    "        partial_val_input = train_scaled[i * num_val_samples : (i+1) * num_val_samples]\n",
    "        partial_val_target = train_target[i * num_val_samples : (i+1) * num_val_samples]\n",
    "\n",
    "        partial_train_input = np.concatenate(\n",
    "            [train_scaled[:i * num_val_samples],\n",
    "            train_scaled[(i+1) * num_val_samples:]],\n",
    "            axis=0\n",
    "        )\n",
    "        partial_train_target = np.concatenate(\n",
    "            [train_target[:i * num_val_samples],\n",
    "            train_target[(i+1) * num_val_samples:]],\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.h5', save_best_only=True) # Declare ModelCheckPoint Callback Object\n",
    "        early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True) # Declare EarlyStopping Callback Object\n",
    "        history = model.fit(\n",
    "            partial_train_input, partial_train_target, epochs=num_epochs, batch_size=batch,\n",
    "            validation_data = (partial_val_input, partial_val_target),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb], verbose = 1) # Train Model\n",
    "\n",
    "    model.evaluate(test_scaled, test_target) # Model Evaluation\n",
    "    end_time = time.time()\n",
    "    print(\"실행시간: \", end_time-start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 학습셋과 검증셋의 손실값 시각화 비교\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label = 'Train')\n",
    "plt.plot(history.history['val_loss'], label = 'Val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습셋과 검증셋의 metrics 시각화 비교\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label = 'Train')\n",
    "plt.plot(history.history['val_accuracy'], label = 'Val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 이미지로 출력해보기\n",
    "plt.imshow(test_scaled[0].reshape(28,28), cmap='gray_r') # 기존 데이터는 합성곱 연산을 위해 임의적으로 3차원을 만들었으나, 원래 데이터는 흑백이므로 색상데이터가 필요없어 2차원 데이터로 변환\n",
    "plt.show()\n",
    "print(test_scaled.shape)\n",
    "\n",
    "# 이미지에 대한 예측 확인하기\n",
    "preds = model.predict(test_scaled) # Keras의 fit()/predict()/evaluate()는 모두 입력의 첫번째 차원이 배치 차원일 것으로 기대함. 따라서 결과 값은 (1, 28, 28, 1)과 같이 더 추가됨. 따라서 슬라이싱을 통해 원소 접근해야 함.\n",
    "print(preds) # 모델의 출력층의 뉴런 갯수에 따라 10개의 클래스에 대한 예측 확률을 출력함 # 여기서는 9번째 값이 1에 가까우므로, 해당 이미지는 9번째 클래스라고 추측가능.\n",
    "\n",
    "# Bar로 클래스 구분짓기\n",
    "plt.bar(0,1, preds)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('prob.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}